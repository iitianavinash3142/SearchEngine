
==Description==

There is a need to develop accurate [[tether]]-less, vision-based articulated body pose estimation systems to recover the pose of bodies such as the human body, a hand, or non-human creatures. Such a system have several foreseeable applications, including 
* Marker-less [[motion capture]] for human-computer interfaces,
* [[Physiotherapy]],
* [[3D animation]],
* [[Ergonomics]] studies,
* [[Robot]] control, and
* Visual surveillance.

One of the major difficulties in recovering pose from images is the high number of degrees-of-freedom (DOF) in the body's movement that has to be recovered. Any rigid object requires six DOF to fully describe its pose, and each additional rigid object connected to it adds at least one DOF. A human body contains no less than 10 large body parts, equating to more than 20 DOF. This difficulty is compounded by the problem of self-occlusion, where body parts [[wikt:occlusion|occlude]] each other depending on the configuration of the parts. Other challenges involve dealing with varying lighting, which affect appearance; varying subject attire or body type; required camera configuration; and required computation time.

The typical articulated body pose estimation system involves a model-based approach, in which an observation is made and provided as input to the model to generate pose estimates. Different kinds of sensors have been explored for use in making the observation, including
* Visible wavelength imagery,
* [[Long-wave]] thermal [[infrared]] imagery,
* [[TOF-camera|Time-of-flight]] imagery, and
* [[Laser range scanner]] imagery.

These sensors produce intermediate representations that is directly used by the model; the representations include
* Image appearance,
* Voxel (volume element) reconstruction,
* 3D surface point clouds, and
* 3D surface meshes.

==Related technology==
A commercially successful but specialized computer vision-based articulated body [[3D Pose Estimation|pose estimation]] technique is optical [[motion capture]]. This approach involves placing markers on the individual at strategic locations to capture the 6 degrees-of-freedom of each body part.

==Active Research Groups==
A number of groups are actively pursuing this topic, including groups in Brown University; Carnegie Mellon University; MPI Saarbruecken; Stanford University; the University of California, San Diego; the Univeresity of Toronto; and the Ecole Centrale de Paris.

==References==
{{Reflist}}

==External links==
*[http://www.cs.brown.edu/people/black/  Michael J. Black, Professor at Brown University]
*[http://www.cs.cmu.edu/~german/research/HumanApp/humanapp.html Research Project Page of German Cheung at Carnegie Mellon University]
*[http://www.mpi-inf.mpg.de/~rosenhahn Homepage of Dr.-Ing at MPI Saarbruecken]
*[http://www.stanford.edu/group/biomotion/currentprojects_Markerless.html Markerless Motion Capture Project at Stanford]
*[http://cvrr.ucsd.edu Computer Vision and Robotics Research Laboratory at the University of California, San Diego]
*[http://www.cs.toronto.edu/~fleet/research/projects.html Research Projects of David J. Fleet at the Univeresity of Toronto]
*[http://hmi.ewi.utwente.nl/person/Ronald%20Poppe Ronald Poppe at the University of Twente].
*[http://vision.mas.ecp.fr Professor Nikos Paragios at the Ecole Centrale de Paris]

